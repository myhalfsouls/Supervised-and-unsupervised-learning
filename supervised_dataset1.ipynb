{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d254b1c-7782-47df-b3b7-5d54c4bd67c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import EpochScoring \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c4eaa4-0317-4722-8d03-44b34d43731e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deae68fa-1c9c-482d-903d-ab1a003c70d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neural network class, code adapted from https://github.com/jlm429/pyperch/blob/master/pyperch/neural/backprop_nn.py\n",
    "\n",
    "class BackpropModule(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_units=10, hidden_layers=1,\n",
    "                 dropout_percent=0, activation=nn.ReLU(), output_activation=nn.Softmax(dim=-1)):\n",
    "        \"\"\"\n",
    "\n",
    "        Initialize the neural network.\n",
    "\n",
    "        PARAMETERS:\n",
    "\n",
    "        input_dim {int}:\n",
    "            Number of features/dimension of the input.  Must be greater than 0.\n",
    "\n",
    "        output_dim {int}:\n",
    "            Number of classes/output dimension of the model. Must be greater than 0.\n",
    "\n",
    "        hidden_units {int}:\n",
    "            Number of hidden units.\n",
    "\n",
    "        hidden_layers {int}:\n",
    "            Number of hidden layers.\n",
    "\n",
    "        dropout_percent {float}:\n",
    "            Probability of an element to be zeroed.\n",
    "\n",
    "        activation {torch.nn.modules.activation}:\n",
    "            Activation function.\n",
    "\n",
    "        output_activation {torch.nn.modules.activation}:\n",
    "            Output activation.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_units = hidden_units\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.dropout = nn.Dropout(dropout_percent)\n",
    "        self.activation = activation\n",
    "        self.output_activation = output_activation\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.device = \"cpu\"\n",
    "\n",
    "        # input layer\n",
    "        self.layers.append(nn.Linear(self.input_dim, self.hidden_units, device=self.device))\n",
    "        # hidden layers\n",
    "        for layer in range(self.hidden_layers):\n",
    "            self.layers.append(nn.Linear(self.hidden_units, self.hidden_units, device=self.device))\n",
    "        # output layer\n",
    "        self.layers.append(nn.Linear(self.hidden_units, self.output_dim, device=self.device))\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        \"\"\"\n",
    "        Recipe for the forward pass.\n",
    "\n",
    "        PARAMETERS:\n",
    "\n",
    "        X {torch.tensor}:\n",
    "            NN input data. Shape (batch_size, input_dim).\n",
    "\n",
    "        RETURNS:\n",
    "\n",
    "        X {torch.tensor}:\n",
    "            NN output data. Shape (batch_size, output_dim).\n",
    "        \"\"\"\n",
    "        X = self.activation(self.layers[0](X))\n",
    "        X = self.dropout(X)\n",
    "        for i in range(self.hidden_layers):\n",
    "            X = self.activation(self.layers[i+1](X))\n",
    "            X = self.dropout(X)\n",
    "        X = self.output_activation(self.layers[self.hidden_layers+1](X))\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e4fd9e-0c3c-4c7e-9c07-8b2f5425485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load bean dataset, binary classification with larger dataset\n",
    " \n",
    "# fetch dataset \n",
    "bean = pd.read_excel('.//datasets//bean//Dry_Bean_Dataset.xlsx')\n",
    "\n",
    "X_bean = bean.iloc[:, :-1]\n",
    "y_bean = bean.iloc[:, -1]\n",
    "\n",
    "encoder = preprocessing.LabelEncoder().fit(y_bean)\n",
    "y_bean = encoder.transform(y_bean)\n",
    "\n",
    "X_bean_train, X_bean_test, y_bean_train, y_bean_test = model_selection.train_test_split(X_bean, y_bean, test_size=0.2, random_state=seed, stratify=y_bean)\n",
    "\n",
    "scaler_bean = preprocessing.StandardScaler().fit(X_bean_train)\n",
    "X_bean_train = scaler_bean.transform(X_bean_train)\n",
    "X_bean_test = scaler_bean.transform(X_bean_test)\n",
    "\n",
    "X_train = X_bean_train.astype(np.float32)\n",
    "X_test = X_bean_test.astype(np.float32)\n",
    "y_train = y_bean_train.astype(np.int64)\n",
    "y_test = y_bean_test.astype(np.int64)\n",
    "\n",
    "bean_y = bean.copy()\n",
    "bean_y.iloc[:, :-1] = scaler_bean.transform(bean_y.iloc[:, :-1])\n",
    "bean_y['Class'] = y_bean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8918c2-ce17-4a32-afb5-94bf187f92cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = X_bean.columns\n",
    "counts = bean['Class'].value_counts().values\n",
    "\n",
    "plt.figure(figsize=(4.8,4.8))\n",
    "plt.bar(np.unique(bean['Class']), counts, width=0.5)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Count')\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(16, 14))\n",
    "axes = axes.flatten()\n",
    "for i, col in enumerate(col_names):\n",
    "    sns.kdeplot(data=bean_y, x=col, hue='Class', ax=axes[i], common_norm=False)\n",
    "    axes[i].set_title(f'{col} distribution');\n",
    "    axes[i].set_xlabel(None)\n",
    "plt.tight_layout()\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "# plt.savefig('bean_feature.png', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d01e07-df18-4483-967d-f2450439a21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize neural net for wine dataset and perform gridsearch\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "NN = NeuralNetClassifier(\n",
    "    module=BackpropModule,\n",
    "    module__input_dim=num_features,\n",
    "    module__output_dim=num_classes,\n",
    "    module__hidden_units=128,\n",
    "    module__hidden_layers=2,\n",
    "    module__dropout_percent=0,\n",
    "    max_epochs=500,\n",
    "    verbose=0,\n",
    "    callbacks=[EpochScoring(scoring='accuracy', name='train_acc', on_train=True),],\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    optimizer=optim.SGD,\n",
    "    optimizer__weight_decay=0,\n",
    "    optimizer__momentum=0,\n",
    "    lr=0.05,\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "NN.set_params(train_split=False, verbose=0)\n",
    "\n",
    "default_params = {\n",
    "    'module__input_dim': [num_features],\n",
    "    'module__output_dim': [num_classes],\n",
    "    'max_epochs': [500]\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'lr': [0.001, 0.01, 0.1],\n",
    "    'module__hidden_units': [16, 32, 64, 128, 256],\n",
    "    'module__hidden_layers': [1, 2, 3],\n",
    "    'module__dropout_percent': [0, 0.1, 0.2, 0.3],\n",
    "    'optimizer__weight_decay': [0, 1e-4, 1e-3, 1e-2],\n",
    "    'optimizer__momentum': [0, 0.9], \n",
    "    **default_params,\n",
    "}\n",
    "\n",
    "folds = StratifiedKFold(n_splits=5)\n",
    "gs_NN = GridSearchCV(NN, params, refit=False, cv=folds, scoring='accuracy', verbose=3, n_jobs=12)\n",
    "\n",
    "gs_NN.fit(X_train, y_train)\n",
    "\n",
    "df = pd.DataFrame(gs_NN.cv_results_)\n",
    "df.to_excel('NN_bean_temp.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62c7b38-605e-4ae1-9359-fd36517d16ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best params for NN \n",
    "\n",
    "NN_best_param = gs_NN.best_params_\n",
    "print(NN_best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04336f46-dcf4-45cc-ae85-21c5277e0974",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_best = NeuralNetClassifier(\n",
    "    module=BackpropModule,\n",
    "    module__input_dim=num_features,\n",
    "    module__output_dim=num_classes,\n",
    "    module__hidden_units=256,\n",
    "    module__hidden_layers=2,\n",
    "    module__dropout_percent=0.1,\n",
    "    max_epochs=200,\n",
    "    verbose=0,\n",
    "    callbacks=[EpochScoring(scoring='accuracy', name='train_acc', on_train=True),],\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    optimizer=optim.SGD,\n",
    "    optimizer__weight_decay=0,\n",
    "    optimizer__momentum=0.9,\n",
    "    lr=0.01,\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    ")\n",
    "\n",
    "# Vary architechture to understand its effects:\n",
    "default_params = {\n",
    "    'module__input_dim': [num_features],\n",
    "    'module__output_dim': [num_classes],\n",
    "    'max_epochs': [500],\n",
    "    'module__dropout_percent': [0.1],\n",
    "    'optimizer__weight_decay': [0],\n",
    "    'optimizer__momentum': [0.9],\n",
    "    'lr': [0.01]\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'module__hidden_units': [8, 16, 32, 64, 128, 256],\n",
    "    'module__hidden_layers': [0, 1, 2, 3],\n",
    "    **default_params,\n",
    "}\n",
    "\n",
    "NN_best_arch = GridSearchCV(NN_best, params, refit=False, cv=folds, scoring='accuracy', verbose=3, n_jobs=12)\n",
    "\n",
    "NN_best_arch.fit(X_train, y_train)\n",
    "\n",
    "df = pd.DataFrame(NN_best_arch.cv_results_)\n",
    "df.to_excel('NN_bean_arch.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cfb20f-a9f2-4ddc-8158-95370c98eb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vary dropout and regularization to understand its effects:\n",
    "default_params = {\n",
    "    'module__input_dim': [num_features],\n",
    "    'module__output_dim': [num_classes],\n",
    "    'max_epochs': [500],\n",
    "    'optimizer__momentum': [0.9],\n",
    "    'lr': [0.01],\n",
    "    'module__hidden_units': [64],\n",
    "    'module__hidden_layers': [1]\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'module__dropout_percent': [0, 0.1, 0.2, 0.3],\n",
    "    'optimizer__weight_decay': [0, 1e-5, 3e-5, 1e-4, 3e-4, 1e-3],\n",
    "    **default_params,\n",
    "}\n",
    "\n",
    "NN_best_reg = GridSearchCV(NN_best, params, refit=False, cv=folds, scoring='accuracy', verbose=3, n_jobs=12)\n",
    "\n",
    "NN_best_reg.fit(X_train, y_train)\n",
    "\n",
    "df = pd.DataFrame(NN_best_reg.cv_results_)\n",
    "df.to_excel('NN_bean_reg.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be678cef-14ed-478f-9647-f687399694a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vary lr to understand its effects:\n",
    "\n",
    "NN_lr_results = {}\n",
    "\n",
    "for lr_range in [0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10]:\n",
    "    NN_lr = NeuralNetClassifier(\n",
    "        module=BackpropModule,\n",
    "        module__input_dim=num_features,\n",
    "        module__output_dim=num_classes,\n",
    "        module__hidden_units=64,\n",
    "        module__hidden_layers=1,\n",
    "        module__dropout_percent=0.1,\n",
    "        max_epochs=500,\n",
    "        verbose=0,\n",
    "        callbacks=[EpochScoring(scoring='accuracy', name='train_acc', on_train=True),],\n",
    "        criterion=nn.CrossEntropyLoss,\n",
    "        optimizer=optim.SGD,\n",
    "        optimizer__weight_decay=0,\n",
    "        optimizer__momentum=0.9,\n",
    "        lr=lr_range,\n",
    "        # Shuffle training data on each epoch\n",
    "        iterator_train__shuffle=True,\n",
    "    )\n",
    "    \n",
    "    NN_lr.fit(X_train, y_train)\n",
    "\n",
    "    NN_lr_results[str(lr_range)+'_train'] = NN_lr.history[:, 'train_acc']\n",
    "    NN_lr_results[str(lr_range)+'_valid'] = NN_lr.history[:, 'valid_acc']\n",
    "\n",
    "df = pd.DataFrame(NN_lr_results)\n",
    "df.to_excel('NN_bean_lr2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e01e86-0069-4c13-8dfc-7ee349818cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparam plots\n",
    "\n",
    "NN_arch_data = pd.read_excel('NN_bean_arch.xlsx')\n",
    "NN_reg_data = pd.read_excel('NN_bean_reg.xlsx')\n",
    "\n",
    "units =  [8, 16, 32, 64, 128, 256]\n",
    "layers = [1, 2, 3]\n",
    "\n",
    "decay =  [1e-6, 1e-5, 3e-5, 1e-4, 3e-4, 1e-3]\n",
    "dps = [0, 0.1, 0.2, 0.3]\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 10.5))\n",
    "ax = ax.flatten()\n",
    "for layer in layers:\n",
    "    val_scores = NN_arch_data.loc[NN_arch_data['param_module__hidden_layers'] == layer, ['mean_test_score']].values\n",
    "    ax[0].plot(units, val_scores, label='layers = '+str(layer))\n",
    "ax[0].set_xlabel('Number of units per layer')\n",
    "ax[0].set_ylabel('Validation accuracy')\n",
    "ax[0].set_xscale('log', base=2)\n",
    "ax[0].set_ylim([0.7, 0.95])\n",
    "ax[0].legend()\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "ax[0].xaxis.set_major_formatter(ScalarFormatter())\n",
    "\n",
    "for dp in dps:\n",
    "    val_scores = NN_reg_data.loc[NN_reg_data['param_module__dropout_percent'] == dp, ['mean_test_score']].values\n",
    "    ax[1].plot(decay, val_scores, label='dp = '+str(dp))\n",
    "ax[1].set_xlabel('Weight decay')\n",
    "ax[1].set_ylabel('Validation accuracy')\n",
    "ax[1].set_xscale('log', base=10)\n",
    "ax[1].set_ylim([0.7, 0.95])\n",
    "ax[1].legend()\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "NN_lr_data = pd.read_excel('NN_bean_lr2.xlsx')\n",
    "\n",
    "lrs = [0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10]\n",
    "for i in range(7):\n",
    "    ax[2].plot(NN_lr_data.iloc[:100, 2*i+1], label='lr = '+str(lrs[i]))\n",
    "ax[2].set_xlabel('Iteration')\n",
    "ax[2].set_ylabel('Training accuracy')\n",
    "ax[2].set_ylim([0.15, 0.95])\n",
    "ax[2].legend()\n",
    "\n",
    "for i in range(7):\n",
    "    ax[3].plot(NN_lr_data.iloc[:100, 2*i+2], label='lr = '+str(lrs[i]))\n",
    "ax[3].set_xlabel('Iteration')\n",
    "ax[3].set_ylabel('Validation accuracy')\n",
    "ax[3].set_ylim([0.15, 0.95])\n",
    "ax[3].legend(loc=4)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig('NN_hyperparams.png', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d015c60-5df1-42b2-845b-e418a10f56db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final NN results\n",
    "\n",
    "NN_best = NeuralNetClassifier(\n",
    "    module=BackpropModule,\n",
    "    module__input_dim=num_features,\n",
    "    module__output_dim=num_classes,\n",
    "    module__hidden_units=64,\n",
    "    module__hidden_layers=1,\n",
    "    module__dropout_percent=0.1,\n",
    "    max_epochs=100,\n",
    "    verbose=0,\n",
    "    callbacks=[EpochScoring(scoring='accuracy', name='train_acc', on_train=True),],\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    optimizer=optim.SGD,\n",
    "    optimizer__weight_decay=0,\n",
    "    optimizer__momentum=0.9,\n",
    "    lr=0.1,\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    ")\n",
    "\n",
    "NN_best.fit(X_train, y_train)\n",
    "\n",
    "# plot the iterative learning curve (accuracy)\n",
    "ax[0].plot(NN_best.history[:, 'train_acc'], label='Train Acc', color='cornflowerblue')\n",
    "ax[0].plot(NN_best.history[:, 'valid_acc'], label='Validation Acc', color='chartreuse')\n",
    "ax[0].set_xlabel(\"Iteration\")\n",
    "ax[0].set_ylabel(\"Accuracy\")\n",
    "ax[0].legend()\n",
    "\n",
    "train_sizes, train_scores, val_scores = learning_curve(NN_best, X_train, y_train, train_sizes=[0.025, 0.05, 0.1, 0.15, 0.2, 0.3, 0.5, 0.75, 1], cv=folds)\n",
    "\n",
    "train_scores_mean = train_scores.mean(axis=1)\n",
    "train_scores_std = train_scores.std(axis=1)\n",
    "val_scores_mean = val_scores.mean(axis=1)\n",
    "val_scores_std = val_scores.std(axis=1)\n",
    "\n",
    "ax[1].fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color='green')\n",
    "ax[1].fill_between(train_sizes, val_scores_mean - val_scores_std, val_scores_mean + val_scores_std, alpha=0.1, color='darkorchid')\n",
    "ax[1].plot(train_sizes, train_scores_mean, label=\"Training Acc\", color='cyan')\n",
    "ax[1].plot(train_sizes, val_scores_mean, label=\"Validation Acc\", color='darkorchid')\n",
    "ax[1].set_xlabel(\"Training size\")\n",
    "ax[1].set_ylabel(\"Accuracy\")\n",
    "ax[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig('NN_final_trains.png', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3434925-42fa-4f73-a04a-11fc56ec68e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "y_test_prob = NN_best.predict_proba(X_test)\n",
    "y_test_pred = np.argmax(y_test_prob, axis=1)\n",
    "NN_test_acc = metrics.accuracy_score(y_test, y_test_pred)\n",
    "NN_test_recall = metrics.recall_score(y_test, y_test_pred, average='macro')\n",
    "NN_test_f1 = metrics.f1_score(y_test, y_test_pred, average='macro')\n",
    "print('Neural network on wine dataset, test accuracy is: {:.3f}'.format(NN_test_acc))\n",
    "print('Neural network on wine dataset, test recall is: {:.3f}'.format(NN_test_recall))\n",
    "print('Neural network on wine dataset, test f1 score is: {:.3f}'.format(NN_test_f1))\n",
    "\n",
    "# confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test_pred, y_test)\n",
    "cm_plot = metrics.ConfusionMatrixDisplay(cm)\n",
    "cm_plot.plot()\n",
    "# cm_plot.figure_.savefig('NN_conf_mat.png', dpi=500)\n",
    "\n",
    "%timeit NN_best.fit(X_train, y_train)\n",
    "%timeit NN_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4df133-994c-470c-8816-6efe514beca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search with SVM\n",
    "\n",
    "SVM = svm.SVC(max_iter=1000000000)\n",
    "\n",
    "params = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'poly', 'rbf'],\n",
    "    'degree': [2, 3, 4],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "}\n",
    "\n",
    "folds = StratifiedKFold(n_splits=5)\n",
    "gs_SVM = GridSearchCV(SVM, params, refit=False, cv=folds, scoring='accuracy', verbose=3, n_jobs=12)\n",
    "\n",
    "gs_SVM.fit(X_train, y_train)\n",
    "\n",
    "df = pd.DataFrame(gs_SVM.cv_results_)\n",
    "df.to_excel('SVM_bean_GS.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96ed9ea-9043-4fa8-88a7-14dfbe1d5015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best params for SVM \n",
    "\n",
    "SVM_best_param = gs_SVM.best_params_\n",
    "print(SVM_best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37688f4-e9fa-4018-ae00-5ca6244decde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparam effects\n",
    "\n",
    "SVM_GS_data = pd.read_excel('SVM_bean_GS.xlsx')\n",
    "SVM_GS_kernel = SVM_GS_data.loc[(SVM_GS_data['param_C'] == 10) & (SVM_GS_data['param_gamma'] == 0.1), ['param_degree', 'param_kernel', 'mean_test_score']]\n",
    "kernels = ['linear', 'poly_2', 'poly_3', 'poly_4', 'rbf']\n",
    "scores = []\n",
    "scores.append(SVM_GS_kernel.loc[SVM_GS_kernel['param_kernel'] == 'linear', ['mean_test_score']].values[0].item())\n",
    "for i in [2, 3, 4]:\n",
    "    scores.append(SVM_GS_kernel.loc[(SVM_GS_kernel['param_kernel'] == 'poly') & (SVM_GS_kernel['param_degree'] == i), ['mean_test_score']].values[0].item())\n",
    "scores.append(SVM_GS_kernel.loc[SVM_GS_kernel['param_kernel'] == 'rbf', ['mean_test_score']].values[0].item())\n",
    "\n",
    "SVM_time = svm.SVC(C=10, gamma=0.1, kernel='linear')\n",
    "%timeit SVM_time.fit(X_train, y_train)\n",
    "SVM_time = svm.SVC(C=10, gamma=0.1, kernel='poly', degree=2)\n",
    "%timeit SVM_time.fit(X_train, y_train)\n",
    "SVM_time = svm.SVC(C=10, gamma=0.1, kernel='poly', degree=3)\n",
    "%timeit SVM_time.fit(X_train, y_train)\n",
    "SVM_time = svm.SVC(C=10, gamma=0.1, kernel='poly', degree=4)\n",
    "%timeit SVM_time.fit(X_train, y_train)\n",
    "SVM_time = svm.SVC(C=10, gamma=0.1, kernel='rbf')\n",
    "%timeit SVM_time.fit(X_train, y_train)\n",
    "fit_times = [418, 369, 289, 458, 346]\n",
    "\n",
    "SVM_poly3 = svm.SVC(kernel='poly', degree=3, max_iter=1000000000)\n",
    "params = {'C': [1e-4, 2e-4, 5e-4, 1e-3, 2e-3, 5e-3, 1e-2, 2e-2, 5e-2, 0.1, 0.2, 0.5, 1, 2, 5, 10, 20, 50, 100, 200, 500, 1000, 2000, 5000, 10000]}\n",
    "SVM_C = GridSearchCV(SVM_poly3, params, refit=False, cv=folds, scoring='accuracy', verbose=3, n_jobs=12)\n",
    "SVM_C.fit(X_train, y_train)\n",
    "df = pd.DataFrame(SVM_C.cv_results_)\n",
    "df.to_excel('SVM_bean_C.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bb60c8-df4c-4aab-8a77-84430b2790bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_best = svm.SVC(kernel='poly', degree=3, C=10)\n",
    "\n",
    "train_sizes, train_scores, val_scores = learning_curve(SVM_best, X_train, y_train, train_sizes=np.linspace(0.05, 1, 20), cv=folds)\n",
    "\n",
    "train_scores_mean = train_scores.mean(axis=1)\n",
    "train_scores_std = train_scores.std(axis=1)\n",
    "val_scores_mean = val_scores.mean(axis=1)\n",
    "val_scores_std = val_scores.std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4196b0-faa5-4271-8b41-5200fc838c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_C_data = pd.read_excel('SVM_bean_C.xlsx')\n",
    "\n",
    "kernels = ['linear', 'poly_2', 'poly_3', 'poly_4', 'rbf']\n",
    "\n",
    "Cs = SVM_C_data['param_C']\n",
    "C_scores = SVM_C_data['mean_test_score']\n",
    "C_times = SVM_C_data['mean_fit_time'] * 1000\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 10.5))\n",
    "ax = ax.flatten()\n",
    "ax[0].bar(kernels, scores, label=kernels)\n",
    "ax[0].set_xlabel('Kernel type')\n",
    "ax[0].set_ylabel('Validation accuracy')\n",
    "ax[0].set_ylim([0, 1])\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "ax[1].bar(kernels, fit_times, label=kernels, color='orange')\n",
    "ax[1].set_xlabel('Kernel type')\n",
    "ax[1].set_ylabel('Model fit runtime (ms)')\n",
    "\n",
    "ln1 = ax[2].plot(Cs, C_scores, label='Accuracy')\n",
    "ax[2].set_xlabel('C')\n",
    "ax[2].set_ylabel('Validation accuracy')\n",
    "ax[2].set_xscale('log', base=10)\n",
    "ax[2].set_ylim([0.25, 1.05])\n",
    "ax2 = ax[2].twinx()\n",
    "ln2 = ax2.plot(Cs, C_times, color='orange', label='Runtime')\n",
    "ax2.set_ylabel('Model fit runtime (ms)')\n",
    "lns = ln1 + ln2\n",
    "labs = [l.get_label() for l in lns]\n",
    "ax2.legend(lns, labs, loc=0)\n",
    "\n",
    "ax[3].fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color='green')\n",
    "ax[3].fill_between(train_sizes, val_scores_mean - val_scores_std, val_scores_mean + val_scores_std, alpha=0.1, color='darkorchid')\n",
    "ax[3].plot(train_sizes, train_scores_mean, label=\"Training score\", color='cyan')\n",
    "ax[3].plot(train_sizes, val_scores_mean, label=\"Validation score\", color='darkorchid')\n",
    "ax[3].set_xlabel(\"Training size\")\n",
    "ax[3].set_ylabel(\"Score\")\n",
    "ax[3].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig('SVM_results.png', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00c350c-8ae9-4366-b059-419b0210155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "SVM_best.fit(X_train, y_train)\n",
    "y_test_pred = SVM_best.predict(X_test)\n",
    "\n",
    "SVM_test_acc = metrics.accuracy_score(y_test, y_test_pred)\n",
    "SVM_test_recall = metrics.recall_score(y_test, y_test_pred, average='macro')\n",
    "SVM_test_f1 = metrics.f1_score(y_test, y_test_pred, average='macro')\n",
    "print('SVM on wine dataset, test accuracy is: {:.3f}'.format(SVM_test_acc))\n",
    "print('SVM on wine dataset, test recall is: {:.3f}'.format(SVM_test_recall))\n",
    "print('SVM on wine dataset, test f1 score is: {:.3f}'.format(SVM_test_f1))\n",
    "\n",
    "# confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test_pred, y_test)\n",
    "cm_plot = metrics.ConfusionMatrixDisplay(cm)\n",
    "cm_plot.plot()\n",
    "# cm_plot.figure_.savefig('SVM_conf_mat.png', dpi=500)\n",
    "\n",
    "%timeit SVM_best.fit(X_train, y_train)\n",
    "%timeit SVM_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30a17ed-7124-4ddf-8ba1-116c0a6b75b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search with kNN\n",
    "\n",
    "kNN = neighbors.KNeighborsClassifier()\n",
    "\n",
    "params = {\n",
    "    'n_neighbors': np.linspace(1, 30, 30, dtype='int').tolist(),\n",
    "    'metric': ['euclidean', 'manhattan', 'cosine'],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "folds = StratifiedKFold(n_splits=5)\n",
    "gs_kNN = GridSearchCV(kNN, params, refit=False, cv=folds, scoring='accuracy', verbose=3, n_jobs=12)\n",
    "\n",
    "gs_kNN.fit(X_train, y_train)\n",
    "\n",
    "df = pd.DataFrame(gs_kNN.cv_results_)\n",
    "df.to_excel('kNN_bean_GS.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0377dd-6e3a-4e03-8442-e705d7d68cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparam effects\n",
    "\n",
    "kNN_GS_data = pd.read_excel('kNN_bean_GS.xlsx')\n",
    "k = np.linspace(1, 30, 30)\n",
    "euc = kNN_GS_data.loc[(kNN_GS_data['param_weights'] == 'uniform') & (kNN_GS_data['param_metric'] == 'euclidean'), ['mean_test_score']].values\n",
    "man = kNN_GS_data.loc[(kNN_GS_data['param_weights'] == 'uniform') & (kNN_GS_data['param_metric'] == 'manhattan'), ['mean_test_score']].values\n",
    "cos = kNN_GS_data.loc[(kNN_GS_data['param_weights'] == 'uniform') & (kNN_GS_data['param_metric'] == 'cosine'), ['mean_test_score']].values\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 10.5))\n",
    "ax = ax.flatten()\n",
    "\n",
    "ax[0].plot(k, euc, label=\"euclidean\")\n",
    "ax[0].plot(k, man, label=\"manhattan\")\n",
    "ax[0].plot(k, cos, label=\"cosine\", color='red')\n",
    "ax[0].set_xlabel(\"k\")\n",
    "ax[0].set_ylabel(\"Validation accuracy\")\n",
    "ax[0].set_ylim([0.875, 0.928])\n",
    "ax[0].legend()\n",
    "\n",
    "euc = kNN_GS_data.loc[(kNN_GS_data['param_weights'] == 'distance') & (kNN_GS_data['param_metric'] == 'euclidean'), ['mean_test_score']].values\n",
    "man = kNN_GS_data.loc[(kNN_GS_data['param_weights'] == 'distance') & (kNN_GS_data['param_metric'] == 'manhattan'), ['mean_test_score']].values\n",
    "cos = kNN_GS_data.loc[(kNN_GS_data['param_weights'] == 'distance') & (kNN_GS_data['param_metric'] == 'cosine'), ['mean_test_score']].values\n",
    "\n",
    "ax[1].plot(k, euc, label=\"euclidean\")\n",
    "ax[1].plot(k, man, label=\"manhattan\")\n",
    "ax[1].plot(k, cos, label=\"cosine\", color='red')\n",
    "ax[1].set_xlabel(\"k\")\n",
    "ax[1].set_ylabel(\"Validation accuracy\")\n",
    "ax[1].set_ylim([0.875, 0.928])\n",
    "ax[1].legend()\n",
    "\n",
    "kNN_best = neighbors.KNeighborsClassifier(n_neighbors=22, metric='euclidean')\n",
    "kNN_best.fit(X_train, y_train)\n",
    "\n",
    "train_sizes, train_scores, val_scores = learning_curve(kNN_best, X_train, y_train, train_sizes=np.linspace(0.05, 1.0, 20), cv=5)\n",
    "\n",
    "train_scores_mean = train_scores.mean(axis=1)\n",
    "train_scores_std = train_scores.std(axis=1)\n",
    "val_scores_mean = val_scores.mean(axis=1)\n",
    "val_scores_std = val_scores.std(axis=1)\n",
    "\n",
    "ax[2].fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color='green')\n",
    "ax[2].fill_between(train_sizes, val_scores_mean - val_scores_std, val_scores_mean + val_scores_std, alpha=0.1, color='darkorchid')\n",
    "ax[2].plot(train_sizes, train_scores_mean, label=\"Training score\", color='cyan')\n",
    "ax[2].plot(train_sizes, val_scores_mean, label=\"Validation score\", color='darkorchid')\n",
    "ax[2].set_xlabel(\"Training size\")\n",
    "ax[2].set_ylabel(\"Score\")\n",
    "ax[2].set_ylim([0.882, 0.932])\n",
    "ax[2].legend()\n",
    "\n",
    "ax[3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig('kNN_results.png', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf20ddc-25be-4d76-80d1-e32286ecf506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "kNN_best.fit(X_train, y_train)\n",
    "y_test_pred = kNN_best.predict(X_test)\n",
    "kNN_test_acc = metrics.accuracy_score(y_test, y_test_pred)\n",
    "kNN_test_recall = metrics.recall_score(y_test, y_test_pred, average='macro')\n",
    "kNN_test_f1 = metrics.f1_score(y_test, y_test_pred, average='macro')\n",
    "print('kNN on wine dataset, test accuracy is: {:.3f}'.format(kNN_test_acc))\n",
    "print('kNN on wine dataset, test recall is: {:.3f}'.format(kNN_test_recall))\n",
    "print('kNN on wine dataset, test f1 score is: {:.3f}'.format(kNN_test_f1))\n",
    "# confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test_pred, y_test)\n",
    "cm_plot = metrics.ConfusionMatrixDisplay(cm)\n",
    "cm_plot.plot()\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "cm_plot.figure_.savefig('kNN_conf_mat.png', dpi=500)\n",
    "\n",
    "%timeit kNN_best.fit(X_train, y_train)\n",
    "%timeit kNN_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2152bb0c-5f05-4c2a-8415-8b00e82b53d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
